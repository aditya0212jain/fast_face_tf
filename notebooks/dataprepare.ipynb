{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WiderDataset:\n",
    "    \"\"\"\n",
    "    [left, top, width, height, score]\n",
    "    \"\"\"\n",
    "    def __init__(self,image_folder_path,label_path):\n",
    "        im_paths = self.get_image_paths(image_folder_path)\n",
    "        image_labels = self.get_labels(label_path)\n",
    "        self.data = self.get_image_unified(im_paths,image_labels)\n",
    "        return \n",
    "        \n",
    "    def get_image_paths(self,folder_path=\"../dataset/Wider/WIDER_train/images/\"):\n",
    "        folders = glob.glob(folder_path+\"*\")\n",
    "        images_paths = []\n",
    "        for folder in folders:\n",
    "            images_paths.extend(glob.glob(os.path.join(folder,'*')))\n",
    "        return images_paths\n",
    "    \n",
    "    def get_labels(self,label_file_path):\n",
    "        label_file = open(label_file_path,'r')\n",
    "        ## Getting image names\n",
    "        image_names = []\n",
    "        flag = False\n",
    "        image_labels = {}\n",
    "        for line in label_file:\n",
    "            sp = line.strip().split('/')\n",
    "            if len(sp)>1:\n",
    "                image_names.append(sp[-1])\n",
    "                image_labels[image_names[-1]] = []\n",
    "            cor = line.strip().split(' ')\n",
    "            if len(cor)==1:\n",
    "                continue\n",
    "            image_labels[image_names[-1]].append([int(val) for val in cor[:4]])\n",
    "        label_file.close()\n",
    "        return image_labels\n",
    "        \n",
    "    def get_image_unified(self,image_paths,image_lables_dict):\n",
    "        data = []\n",
    "        for im_p in image_paths:\n",
    "            im_name = im_p.strip().split('/')[-1]\n",
    "            data_object = {}\n",
    "            data_object['path'] = im_p\n",
    "            data_object['bbox'] = image_lables_dict[im_name]\n",
    "            data.append(data_object)\n",
    "        return data\n",
    "    \n",
    "    def get_item(self,i,style='anchor'):\n",
    "        image = np.array(Image.open(self.data[i]['path']))\n",
    "        label = self.data[i]['bbox']\n",
    "        if style=='anchor':\n",
    "            label = self.get_anchor_type(label)\n",
    "        ### do the preprocessing on the image here\n",
    "        ## TODO \n",
    "        # image = self.preprocess(image)\n",
    "        return image,label\n",
    "    \n",
    "    def get_anchor_type(self,labels):\n",
    "        new_label = []\n",
    "        for l in labels:\n",
    "            new_label.append([l[0],l[1],l[0]+l[2],l[1]+l[3]])\n",
    "        return new_label\n",
    "        \n",
    "    \n",
    "    def preprocess(self,image):\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = \"../../dataset/Wider/WIDER_train/images/\"\n",
    "label_path = \"../../dataset/Wider/wider_face_split/wider_face_train_bbx_gt.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "widerDataset = WiderDataset(image_folder_path,label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = widerDataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '../../dataset/Wider/WIDER_train/images/30--Surgeons/30_Surgeons_Surgeons_30_568.jpg',\n",
       " 'bbox': [[356, 74, 90, 132]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = widerDataset.get_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['stride1','stride2']\n",
    "y = [[1,23,3],[4,5,6]]\n",
    "z = dict(zip(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stride1': [1, 23, 3], 'stride2': [4, 5, 6]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class maviData:\n",
    "    \"\"\"\n",
    "    [left, top, width, height, score]\n",
    "    each object : {'bbox': ,'path':}\n",
    "    \"\"\"\n",
    "    def __init__(self,image_root_dir,annotations_root_dir):\n",
    "        im_paths = glob.glob(image_root_dir+\"*\")\n",
    "        image_labels = self.get_labels(annotations_root_dir)\n",
    "        self.data = self.get_image_unified(im_paths,image_labels)\n",
    "        return\n",
    "        \n",
    "    def get_labels(self,annotations_root_dir):\n",
    "        ann_locs = glob.glob(annotations_root_dir+\"*\")\n",
    "        image_labels ={}\n",
    "        for ann in ann_locs:\n",
    "            bboxs = self.get_topLeftWidthHeight(ann)\n",
    "            im = self.get_last(ann)[:-4]\n",
    "            image_labels[im] = bboxs\n",
    "        return image_labels\n",
    "    \n",
    "    def get_image_unified(self,im_paths,image_labels):\n",
    "        data = []\n",
    "        for path in im_paths:\n",
    "#             print(path)\n",
    "            dataObject = {}\n",
    "            dataObject['path'] = path\n",
    "            dataObject['bbox'] = image_labels[self.get_last(path)[:-4]]\n",
    "            if dataObject['bbox']:\n",
    "                data.append(dataObject)\n",
    "        return data\n",
    "        \n",
    "    def get_item(self,i,style='anchor'):\n",
    "        image = np.array(Image.open(self.data[i]['path']))\n",
    "        label = self.data[i]['bbox']\n",
    "        if style=='anchor':\n",
    "            label = self.get_anchor_type(label)\n",
    "        ### do the preprocessing on the image here\n",
    "        ## TODO \n",
    "        # image = self.preprocess(image)\n",
    "        return image,label\n",
    "    \n",
    "    def get_anchor_type(self,labels):\n",
    "        new_label = []\n",
    "        for l in labels:\n",
    "            new_label.append([l[0],l[1],l[0]+l[2],l[1]+l[3]])\n",
    "        return new_label\n",
    "        \n",
    "    \n",
    "    def preprocess(self,image):\n",
    "        return image\n",
    "    \n",
    "    def get_topLeftWidthHeight(self,filepath):\n",
    "        tree = ET.parse(filepath)\n",
    "        root = tree.getroot()\n",
    "        annotations = []\n",
    "        for bndbox in root.findall('object/bndbox'):\n",
    "            xmin = bndbox.find('xmin').text\n",
    "            xmax = bndbox.find('xmax').text\n",
    "            ymin = bndbox.find('ymin').text\n",
    "            ymax = bndbox.find('ymax').text\n",
    "            x = xmin\n",
    "            y = ymin \n",
    "            w = str(int(xmax) - int(xmin))\n",
    "            h = str(int(ymax) - int(ymin))\n",
    "            annotations.append((int(x),int(y),int(w),int(h)))\n",
    "        return annotations\n",
    "    \n",
    "    def get_last(self,x):\n",
    "        a = x.split('/')[-1]\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_loc = \"../../dataset/images/\"\n",
    "annotation_loc = \"../../dataset/annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mData = maviData(image_loc,annotation_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mData.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '../../dataset/images/2019-06-17 15_01_25__018426__44841b92-90d1-11e9-8b8d-dd1eda89fb93.jpg',\n",
       " 'bbox': [(447, 156, 49, 59)]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mData.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting for test and train 20:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impaths = glob.glob(image_loc+\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(impaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impaths_train = impaths[:int(len(impaths)*0.8)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(impaths_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impaths_test = impaths[int(len(impaths)*0.8)-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(impaths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loc = \"../../dataset/train_split_images/\"\n",
    "# test_loc = \"../../dataset/test_split_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in impaths_train:\n",
    "#     shutil.copy2(i,train_loc)\n",
    "# for j in impaths_test:\n",
    "#     shutil.copy2(j,test_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensor_g)",
   "language": "python",
   "name": "tensor_g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
